<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3rd Workshop on Image/Video/Audio Quality in Computer Vision and Generative AI</title>
    <link rel="stylesheet" href="styles.css">
    <script src="script.js"></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>3rd Workshop on Image/Video/Audio Quality in Computer Vision and Generative AI</h1>
            <p></p>
            <p>Workshop Date: Jan 03 or Jan 07, 2024</p>
            <p>Location: WAIKOLOA, HAWAII</p>
            <p>Held in conjunction with <a href="https://wacv2024.thecvf.com/">WACV2024</a></p>
        </div>
    </header>

    <nav class="main-nav">
        <div class="menu-toggle">
            <div class="icon"></div>
        </div>
        <ul class="nav-list">
            <li><a href="index.html">Home</a></li>
            <li><a href="#Submission">Paper Submission</a></li>
            <li><a href="#Competition">Competition</a></li>
            <li><a href="#Organizer">Organizer</a></li>
            <li><a href="#Keynotes">Keynotes</a></li>
            <li><a href="#Information">Other information</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </nav>


    <section id="Home" class="home-section">
        <h2>Home</h2>
        <p>Welcome to the 3rd Workshop on Image/Video/Audio Quality in Computer Vision and Generative AI!</p>
        <h3>Workshop Topics: </h3>
        <p>This workshop addresses topics related to image/video/audio quality in machine learning, computer vision, and generative AI. The topics include, but are not limited to:</p>
        <ul>
                    <li>Impact of image/video/audio quality in traditional machine learning and computer vision use cases such as object detection, segmentation, tracking, and recognition;</li>
                    <li>Analyze, model and learn the quality impact from image/video/audio acquisition, compression, transcoding, transmission, decoding, rendering, and/or display;</li>
                    <li>Techniques used to improve image/video/audio quality in terms of
                        <ul>
                            <li>brightening, color adjustment, sharpening, inpainting, deblurring, denoising, de-hazing, de-raining, demosaicing;</li>
                            <li>removing artifacts such as shadows, glare, and reflections, etc.;</li>
                            <li>resolution, frame rate, color gamut, dynamic range (SDR vs. HDR), etc.;</li>
                            <li>noise/echo cancellation, speech enhancement, etc.;</li>
                            <li>Film grain preservation and synthesis</li>
                        </ul>
                    </li>
                    <li>Novel image/video/audio quality assessment methodologies: full reference, reduced-reference, non-reference, and hybrid models;</li>
                    <li>Techniques to detect and mitigate audio/video synchronization issue and defects;</li>
                    <li>Techniques to measure the quality consistency across different types of video contents (such as ads, movies, sports, etc.) within a single streaming session;</li>
                    <li>Impact of image/video/audio quality in multi-modal use cases;</li>
                    <li>Evaluate image/video/audio quality produced by generative AI, and the impact of input image/video/audio quality on generative AI output;</li>
                    <li>Subjective image/video/audio quality data creation, cleaning, and validation in both lab and crowd-sourcing setups;</li>
                    <li>Datasets, statistics, and theory of image/video/audio quality;</li>
                    <li>Research, applications and system development of the above.</li>
        </ul>
    </section>

    <section id="Submission">
        <h2>Submission</h2>
        <ul>
            <li>Authors are encouraged to submit high-quality, original (i.e., not been previously published or accepted for publication in substantially similar form in any peer-reviewed venue including journal, conference or workshop) research.
            <li>All submissions should follow the same template as for the main WACV2024 conference. The author kit/paper template is provided in Latex format via this overleaf template and this github repository.
            <li>The main paper has an 8-page limit, references do not count toward this. There is no limit on the number of pages in the supplementary material. Only pdf files are accepted.
            <li>Unlike the main conference(WACV2024), the review process for this workshop has only one round, and is single-blind. Authors do not have to be anonymized when submitting their work. 
            <li>Please submit your paper via this link: 
            <li>Authors of accepted papers will be notified via email by:  
        </ul>
    </section>

    <section id="Competition">
        <h2>Competition</h2>
        <p>As part of the workshop,  we plan to host a Grand Challenge on the topic of Content-agnostic Audio and Video Synchronization  (AV-Sync) Detection and Measurement.  Both academic and industrial researchers and teams are invited to submit their original and innovative  algorithms/models (using the latest machine learning and computer vision technologies) and compete for the best model for detecting and/or measuring AV-Sync errors for video streaming applications.  Two competition categories are planned: (1) AV-Sync Error Detection (i.e. detecting the existence of AV-Sync error), and (2) AV-Sync Error Measurement (i.e. predicting the quantitative measure of the AV-Sync error).  The submitted algorithms/models should be applicable to diverse video contents including sports, movies and ads, etc. (i.e. NOT limited to talking head scenes).  The grand challenge team will gather the relevant AV-Sync training and testing datasets and will publish the grand challenge topics, the associated datasets and evaluation metrics upon the acceptance and approval of our workshop proposal. </p>
    </section>

    <section id="Organizer">
        <h2>Organizers</h2>
        <div class="organizer-row">
            <div class="organizer">
                <img src="organizer_1.png" alt="Organizer 1">
                <h3>Yarong Feng</h3>
                <p>Amazon</p>
            </div>
            <div class="organizer">
                <img src="organizer_2.png" alt="Organizer 2">
                <h3>Yuan Ling</h3>
                <p>Amazon</p>
            </div>
        </div>
        <div class="organizer-row">
            <div class="organizer">
                <img src="organizer_3.jpeg" alt="Organizer 3">
                <h3>Joe Liu</h3>
                <p>Amazon</p>
            </div>
            <div class="organizer">
                <img src="organizer_4.png" alt="Organizer 4">
                <h3>Hai Wei</h3>
                <p>Amazon</p>
            </div>
            <div class="organizer">
                <img src="organizer_5.png" alt="Organizer 5">
                <h3>David Higham</h3>
                <p>Amazon</p>
            </div>
        </div>
    </section>


    <section id="Keynotes">
        <h2>Keynotes</h2>
        <p>TBD</p>
    </section>

    <section id="Information">
        <h2>Information</h2>
        <p>TBD</p>
        </table>
    </section>

    <section id="contact">
        <h2>Contact Us</h2>
        <p>If you have any questions or inquiries, please contact us at <a href="mailto:wacv2024-ws-iva-quality@amazon.com">wacv2024-ws-iva-quality@amazon.com</a>.</p>
    </section>

    <footer>
        <p>&copy; 3rd Workshop on Image/Video/Audio Quality in Computer Vision and Generative AI. All rights reserved.</p>
    </footer>
</body>
</html>
